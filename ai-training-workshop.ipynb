{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# LLM and data extraction\n",
    "\n",
    "In this notebook, we will explore how to use the Gemini API to extract metadata from invoices. We will use a PDF file as input and convert it to markdown text. Then, we will use the Gemini API to extract the vendor name, the buyer name and the total amount due from the markdown text.\n",
    "\n",
    "We will compare different methods to extract metadata from scientific papers using the Gemini API, including:\n",
    "1. Asking the API to extract the metadata directly from the markdown text.\n",
    "2. Asking the API to extract the metadata and return the result in JSON format.\n",
    "3. Using a JSON schema to define the expected output format.\n",
    "4. Using function calls to extract metadata from the markdown text.\n",
    "\n",
    "In all the following exemple we'll extract the same information on all these articles:\n",
    "- Vendor Name\n",
    "- Buyer Name\n",
    "- Total Amount Due"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Why JSON?\n",
    "\n",
    "- **Interoperability**: JSON is language-agnostic and easily parsed in Python, R, and other languages.\n",
    "- **API Integration**: Many data sources and web services provide data in JSON format, making it essential for fetching and processing external data.\n",
    "- **Hierarchical Structure**: Supports nested data, making it ideal for representing complex datasets like configurations or structured logs.\n",
    "- **Integration with Pandas**: Python's `pandas` library provides seamless methods (`pd.read_json`, `to_json`) for handling JSON data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Initialize the Google client and load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install ipykernel\n",
    "!pip install google-genai\n",
    "!pip install -U pymupdf4llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import pymupdf4llm\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_KEY = getpass.getpass(\"Enter your password: \")\n",
    "LOCATION = 'europe-west1'\n",
    "MODEL = 'gemini-2.0-flash'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Load pdf and convert to markdown\n",
    "\n",
    "Let's look at the content of `sample-invoice-1` and `sample-invoice-2` and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render String into Markdown\n",
    "def print_md(markdown_text):\n",
    "    display(Markdown(markdown_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PDF file\n",
    "pdf_path = \"./data/\"\n",
    "pdf_filename = \"sample-invoice-1.pdf\"\n",
    "\n",
    "markdown_text = pymupdf4llm.to_markdown(os.path.join(pdf_path, pdf_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the output to a markdown file\n",
    "with open(f\"output/{pdf_filename}-markdown.md\", \"w\") as f:\n",
    "    f.write(markdown_text)\n",
    "\n",
    "print_md(markdown_text[:380])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "#### **Exercise #1**: Convert Invoice 2 from PDF to Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Default extraction\n",
    "\n",
    "In this case, we will provide a prompt asking the API to extract the title, authors, and abstract from the markdown text. No extra indications are given to the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generates Content given a prompt\n",
    "def generate_completion(message: str):\n",
    "    response = client.models.generate_content(model=MODEL, contents = message)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a document processing assistant. I have extracted the following markdown text from a PDF.\n",
    "Please extract the following details:\n",
    "- Vendor Name\n",
    "- Buyer Name\n",
    "- Total Amount Due\n",
    "\n",
    "Markdown text:\n",
    "{markdown_text}\n",
    "\"\"\"\n",
    "\n",
    "response = generate_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_md(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [],
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### Result\n",
    "\n",
    "We can see here that the LLM model was able to extract the **Vendor Name**, **the Buyer Name** and the **Total Amount Due** from the markdown text. The result is returned as plain text in a markdown format. \n",
    "\n",
    "This format is not very structured and may require additional processing to extract the information.\n",
    "\n",
    "> Let's request an easily digestible format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Asking for JSON format\n",
    "\n",
    "Here we're adding one step more. We're asking the LLM to return the result in JSON format. This way we can have a more structured output and it will be easier to extract the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a document processing assistant. I have extracted the following markdown text from a PDF.\n",
    "Please extract the following details:\n",
    "- Vendor Name\n",
    "- Buyer Name\n",
    "- Total Amount Due\n",
    "\n",
    "Markdown text:\n",
    "{markdown_text}\n",
    "\n",
    "Give me the result in JSON format.\n",
    "\"\"\"\n",
    "\n",
    "response = generate_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the markdown code block markers\n",
    "json_str = re.sub(r\"^```(?:json)?\\s*\", \"\", response)\n",
    "json_str = re.sub(r\"\\s*```$\", \"\", json_str)\n",
    "\n",
    "# Parse the JSON string\n",
    "json.loads(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "#### **Exercise #2:** Also ask for the Invoice Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using regex we were able to parse the string into a json format. \n",
    ">However, we can get this structured output directly when calling google's API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Adding a response format as a parameter\n",
    "\n",
    "Google Gemini allows us to specify the response format to be \"json_object\". This way we can force the model to return the result in JSON format. That way the parsing of the result will be easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generates a json given a prompt\n",
    "def generate_completion_json(message: str):\n",
    "    response = client.models.generate_content(model=MODEL, contents = message, config={\"response_mime_type\": \"application/json\"})\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a document processing assistant. I have extracted the following markdown text from a PDF.\n",
    "Please extract the following details:\n",
    "- Vendor Name\n",
    "- Buyer Name\n",
    "- Total Amount Due\n",
    "\n",
    "Markdown text:\n",
    "{markdown_text}\n",
    "\n",
    "Give me the result in JSON format.\n",
    "\"\"\"\n",
    "\n",
    "response = generate_completion_json(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "#### **Exercise #3:** Also ask for the Invoice Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "This time the result is returned in JSON format as requested. We can directly parse the JSON object to extract the information using `json.loads()`. \n",
    "\n",
    "**However**, there is no guarantee that the JSON object will have the expected structure. The model may return the data in a different format than the one we expect for exemple with different casing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Function calling\n",
    "\n",
    "You can specify to the llm to call a function to extract the information. This way you can define the function signature and the llm will call the function with the extracted information.\n",
    "\n",
    "![Tool Calling](./images/tool_calling.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "invoice_extraction = {\n",
    "    \"name\": \"extract_invoice_data\",\n",
    "    \"description\": \"Extract key information from an invoice.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"vendor_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the vendor in the invoice.\",\n",
    "            },\n",
    "            \"buyer_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the buyer in the invoice.\",\n",
    "            },\n",
    "            \"total_amount_due\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The total amount due in the invoice.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"vendor_name\", \"buyer_name\", \"total_amount_due\"],\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_completion_tool_calls(message: str):\n",
    "    tools = genai.types.Tool(function_declarations=[invoice_extraction])\n",
    "    response = client.models.generate_content(model=MODEL, \n",
    "                                              contents = message, \n",
    "                                              config = genai.types.GenerateContentConfig(tools=[tools]))\n",
    "    return response.candidates[0].content.parts[0].function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a document processing assistant. I have extracted the following markdown text from a PDF.\n",
    "Please extract the following details:\n",
    "- Vendor Name\n",
    "- Buyer Name\n",
    "- Total Amount Due\n",
    "\n",
    "Markdown text:\n",
    "{markdown_text}\n",
    "\"\"\"\n",
    "\n",
    "response = generate_completion_tool_calls(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "#### **Exercise #4** Also ask for the Invoice Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Custom json schema (Optional)\n",
    "\n",
    "This time we'll pass a json schema to the model as defined here: https://json-schema.org/. This way we can force the model to return the result in a specific structure, provide default values, descriptions and types for each field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generates a json given a prompt and a schema\n",
    "def generate_completion_json_schema(message: str, schema: dict):\n",
    "    response = client.models.generate_content(model=MODEL, contents = message, config={\"response_mime_type\": \"application/json\",\n",
    "                                                                                       \"response_schema\": schema})\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = {\n",
    "            \"type\": \"object\",\n",
    "            \"description\": \"Metadata from an invoice including its vendor name, buyer name and total amount due.\",\n",
    "            \"properties\": {\n",
    "                \"vendor_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the vendor in the invoice.\",\n",
    "                    \"default\": \"Unknown\",\n",
    "                },\n",
    "                \"buyer_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the buyer in the invoice.\",\n",
    "                },\n",
    "                \"total_amount_due\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The total amount due in the invoice.\",\n",
    "                },\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a document processing assistant. I have extracted the following markdown text from a PDF.\n",
    "Please extract the following details:\n",
    "- Vendor Name\n",
    "- Buyer Name\n",
    "- Total Amount Due\n",
    "\n",
    "Markdown text:\n",
    "{markdown_text}\n",
    "\n",
    "Give me the result in JSON format.\n",
    "\"\"\"\n",
    "\n",
    "response = generate_completion_json_schema(prompt, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Result\n",
    "\n",
    "Now the output will always correspond to the expected schema. Since everything is provided the model doesn't have to guess the shape or part of the shape of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Cost\n",
    "\n",
    "Let's compute the cost of the completion. We'll use the following pricing: https://openai.com/api/pricing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_gemini_2_flash_cost(message: str, verbose: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Computes the cost for the 'gemini-2.0-flash' model based on the completion object.\n",
    "\n",
    "    Args:\n",
    "        completion: The completion object returned by the Gemini API.  This object\n",
    "                    should have a 'usage' attribute with 'prompt_tokens' and\n",
    "                    'completion_tokens' attributes.\n",
    "        verbose:  If True, prints the token counts and estimated cost to the console.\n",
    "                  Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        The estimated cost in US dollars (USD) as a float.\n",
    "    \"\"\"\n",
    "    tools = genai.types.Tool(function_declarations=[invoice_extraction])\n",
    "    completion = client.models.generate_content(model=MODEL, \n",
    "                                                  contents = message, \n",
    "                                                  config = genai.types.GenerateContentConfig(tools=[tools]))\n",
    "    input_tokens = completion.usage_metadata.prompt_token_count\n",
    "    output_tokens = completion.usage_metadata.candidates_token_count\n",
    "\n",
    "    #  Always check the official\n",
    "    #  Google Cloud documentation for the most up-to-date pricing.\n",
    "    cost_per_1M_input_tokens = 0.10  \n",
    "    cost_per_1M_output_tokens = 0.40 \n",
    "\n",
    "    total_cost = (input_tokens / 1e6) * cost_per_1M_input_tokens\n",
    "    total_cost += (output_tokens / 1e6) * cost_per_1M_output_tokens\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Total input tokens: {input_tokens}\")\n",
    "        print(f\"Total output tokens: {output_tokens}\")\n",
    "        print(f\"Total tokens: {input_tokens + output_tokens}\")\n",
    "        print(f\"Estimated cost: ${total_cost:.4f}\")\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_gemini_2_flash_cost(prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "As you can see the major part of the cost is the input tokens. Here we're passing the whole document to the llm which make up for more than 90% of the cost. \n",
    "\n",
    "> How could we reduce the costs of the LLM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Structured output help the LLM to produce better and more interpretable results. On the chart below you'll find the relative performances in terms of reliability of the output matching the expected json format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output_reliability](images/output_reliability.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### **Extra Exercise:** Also ask to return the list of items, and respective price\n",
    "<div>\n",
    "  <input type=\"checkbox\" name=\"uchk\">\n",
    "  <label for=\"uchk\">Response also returns the list of items, and respective price</label>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
